{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05667912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”µ Loading Tokenizer and Data...\n",
      "Tokenizer Loaded. Vocab Size: 10224\n",
      "ğŸš€ Starting Generation for 9 Models...\n",
      "\n",
      "ğŸ“ Generating with: RNN + Adam\n",
      "\n",
      "ğŸ“ Generating with: RNN + RMSprop\n",
      "\n",
      "ğŸ“ Generating with: RNN + SGD\n",
      "\n",
      "ğŸ“ Generating with: LSTM + Adam\n",
      "\n",
      "ğŸ“ Generating with: LSTM + RMSprop\n",
      "\n",
      "ğŸ“ Generating with: LSTM + SGD\n",
      "\n",
      "ğŸ“ Generating with: Transformer + Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherr\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'token_and_position_embedding', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sherr\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'transformer_block', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sherr\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'transformer_block_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sherr\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "\n",
      "ğŸ“ Generating with: Transformer + RMSprop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherr\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'token_and_position_embedding_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sherr\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'transformer_block_2', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sherr\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'transformer_block_3', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Generating with: Transformer + SGD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherr\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'token_and_position_embedding_2', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sherr\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'transformer_block_4', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sherr\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'transformer_block_5', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Generation Complete! Saved to ../results/generated_text/all_generations.csv\n",
      "  Model Optimizer                                     Generated Text\n",
      "0   RNN      Adam  Ù…Ø­Ø¨Øª Ù…ÛŒÚº ÛÛ’ Ø¨Ø§Øª ÛÛŒ ÛÛŒ Ø³Ø§ Ø§Ø³ÛŒ Ú©Ùˆ Ø¢ ÛÛ’ Ú©ÛŒØ§ ÙˆÛ ÛŒÛ...\n",
      "1   RNN      Adam  Ù…Ø­Ø¨Øª ÙˆÙ„ÛŒ ÛŒÛ Ø¬Ø¨ Ù„ÙØ¸ Ø§Ø³ ÛÛŒ Ù†Û ÛÙ…Ø§Ø±ÛŒ Ø¯ÛŒÚ©Ú¾ØªØ§ Ú©Û’ ÛŒØ§...\n",
      "2   RNN      Adam  Ù…Ø­Ø¨Øª Ø¢ Ù‚Ø¯Ø± Ø³Ù…Ø§ Ùˆ Ø¢Ø²Ù…Ø§Ø¦Ø´ Ø³Ø±Ø´Ø§Ø± Ø³Ù…Ø§Ù†Û’ Ø§ÙØ³ÙˆÙ† Ù‚Ø¨Ù„Û...\n",
      "3   RNN      Adam  Ø¯Ù„ Ø¯ÛŒØ§ ØªÙˆ ÛÛ’ Ù†ÛÛŒÚº ÛÛ’ Ø¨Ø³ Ø¨Ú¾ÛŒ Ú©Û Ø¹Ø´Ù‚ ØªÙˆ Ø§Ø³ Ø³Û’ Ù…Ø±...\n",
      "4   RNN      Adam  Ø¯Ù„ Ù„ÛŒØ§ Ú©Ø§Ø³Û‚ ÛÙ… Ø³Û’ Ø§Ù¾Ù†ÛŒ Ø¸Ù„Ù… Ù†ÛÛŒÚº Ú©Û Ø±Ø§Û Ù…ÛŒÚº Ù…Ø¬Ú¾...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, MultiHeadAttention, Dropout, Embedding, Input, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "SEED_TEXTS = [\"Ù…Ø­Ø¨Øª\", \"Ø¯Ù„\", \"Ø´Ø§Ù…\", \"ÛŒØ§Ø¯\", \"Ø®ÙˆØ´ÛŒ\"] \n",
    "TEMPERATURES = [0.7, 1.0, 1.3]\n",
    "NEXT_WORDS = 15 \n",
    "\n",
    "os.makedirs('../results/generated_text', exist_ok=True)\n",
    "\n",
    "print(\" Loading Tokenizer and Data...\")\n",
    "with open('../models/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "data = np.load('../data/processed/ready_data.npz')\n",
    "max_sequence_len = data['X_train'].shape[1] + 1 \n",
    "print(f\"Tokenizer Loaded. Vocab Size: {len(tokenizer.word_index)}\")\n",
    "\n",
    "# Defining custom layers for Transformer model\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1, **kwargs):\n",
    "        super(TransformerBlock, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.rate = rate\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = Sequential([Dense(ff_dim, activation=\"relu\"), Dense(embed_dim),])\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"ff_dim\": self.ff_dim,\n",
    "            \"rate\": self.rate,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class TokenAndPositionEmbedding(Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim, **kwargs):\n",
    "        super(TokenAndPositionEmbedding, self).__init__(**kwargs)\n",
    "        self.maxlen = maxlen\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.token_emb = Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"maxlen\": self.maxlen,\n",
    "            \"vocab_size\": self.vocab_size,\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "#Generation functions\n",
    "\n",
    "def generate_poetry(model, seed_text, next_words, temperature, max_sequence_len):\n",
    "    output_text = seed_text # Starting with the seed text we want to generate from\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([output_text])[0] # Convert current text which is a string to sequence of tokens \n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre') # Pad sequences to the required length\n",
    "        \n",
    "        predictions = model.predict(token_list, verbose=0)[0] # Getting model predictions for the next word \n",
    "        predictions = np.log(predictions + 1e-7) / temperature # Apply temperature to the logits to control the randomness of the predictions\n",
    "        exp_preds = np.exp(predictions) # Exponentiate the logits\n",
    "        predictions = exp_preds / np.sum(exp_preds) # Normalize to get probabilities\n",
    "        \n",
    "        predicted_id = np.random.choice(len(predictions), p=predictions) # Sample the next word ID based on probabilities\n",
    "        \n",
    "        predicted_word = \"\" # Finding  the word corresponding to the predicted ID\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted_id:\n",
    "                predicted_word = word\n",
    "                break\n",
    "        \n",
    "        if predicted_word == \"\": break\n",
    "        output_text += \" \" + predicted_word\n",
    "        \n",
    "    return output_text\n",
    "\n",
    "#  Generation loop\n",
    "\n",
    "models_to_test = [\"RNN\", \"LSTM\", \"Transformer\"]\n",
    "optimizers_to_test = [\"Adam\", \"RMSprop\", \"SGD\"]\n",
    "\n",
    "full_generation_log = []\n",
    "\n",
    "print(f\"Starting Generation for {len(models_to_test) * len(optimizers_to_test)} Models...\")\n",
    "\n",
    "for model_name in models_to_test:\n",
    "    for opt_name in optimizers_to_test:\n",
    "        model_filename = f\"../models/{model_name}_{opt_name}.keras\"\n",
    "        \n",
    "        if not os.path.exists(model_filename):\n",
    "            print(f\"âš ï¸ Model not found: {model_filename}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n Generating with: {model_name} + {opt_name}\")\n",
    "        \n",
    "        try:\n",
    "            model = load_model(model_filename, custom_objects={\n",
    "                'TokenAndPositionEmbedding': TokenAndPositionEmbedding,\n",
    "                'TransformerBlock': TransformerBlock\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\" Error loading {model_name}: {e}\")\n",
    "            continue\n",
    "\n",
    "        for seed in SEED_TEXTS:\n",
    "            for temp in TEMPERATURES:\n",
    "                try:\n",
    "                    generated_text = generate_poetry(model, seed, NEXT_WORDS, temp, max_sequence_len)\n",
    "                    full_generation_log.append({\n",
    "                        \"Model\": model_name,\n",
    "                        \"Optimizer\": opt_name,\n",
    "                        \"Seed\": seed,\n",
    "                        \"Temperature\": temp,\n",
    "                        \"Generated Text\": generated_text\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"Error generating: {e}\")\n",
    "\n",
    "# Saving results\n",
    "df_results = pd.DataFrame(full_generation_log)\n",
    "df_results.to_csv('../results/generated_text/all_generations.csv', index=False)\n",
    "\n",
    "print(\"\\n Generation Complete! Saved to ../results/generated_text/all_generations.csv\")\n",
    "print(df_results[['Model', 'Optimizer', 'Generated Text']].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
