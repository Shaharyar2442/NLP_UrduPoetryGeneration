{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fbb589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”µ Loading Standard Dataset...\n",
      " Starting 15 Hyperparameter Experiments...\n",
      "\n",
      "âš¡ RUNNING EXP-01: RNN | Change layers -> 1\n",
      "Epoch 1/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 26ms/step - accuracy: 0.0362 - loss: 7.1683 - val_accuracy: 0.0439 - val_loss: 6.8662\n",
      "Epoch 2/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 28ms/step - accuracy: 0.0439 - loss: 6.8118 - val_accuracy: 0.0497 - val_loss: 6.7568\n",
      "Epoch 3/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 28ms/step - accuracy: 0.0529 - loss: 6.6959 - val_accuracy: 0.0640 - val_loss: 6.6449\n",
      "Epoch 4/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 29ms/step - accuracy: 0.0688 - loss: 6.5578 - val_accuracy: 0.0717 - val_loss: 6.5703\n",
      "Epoch 5/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 30ms/step - accuracy: 0.0778 - loss: 6.4559 - val_accuracy: 0.0746 - val_loss: 6.5239\n",
      "Epoch 6/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 29ms/step - accuracy: 0.0836 - loss: 6.3794 - val_accuracy: 0.0778 - val_loss: 6.4912\n",
      "Epoch 7/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 29ms/step - accuracy: 0.0873 - loss: 6.3168 - val_accuracy: 0.0807 - val_loss: 6.4756\n",
      "Epoch 8/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 30ms/step - accuracy: 0.0907 - loss: 6.2623 - val_accuracy: 0.0827 - val_loss: 6.4551\n",
      "Epoch 9/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 31ms/step - accuracy: 0.0946 - loss: 6.2121 - val_accuracy: 0.0838 - val_loss: 6.4434\n",
      "Epoch 10/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 31ms/step - accuracy: 0.0981 - loss: 6.1645 - val_accuracy: 0.0842 - val_loss: 6.4334\n",
      "Epoch 11/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 32ms/step - accuracy: 0.1006 - loss: 6.1214 - val_accuracy: 0.0851 - val_loss: 6.4269\n",
      "Epoch 12/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 32ms/step - accuracy: 0.1034 - loss: 6.0804 - val_accuracy: 0.0870 - val_loss: 6.4233\n",
      "Epoch 13/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 32ms/step - accuracy: 0.1067 - loss: 6.0385 - val_accuracy: 0.0858 - val_loss: 6.4227\n",
      "Epoch 14/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 32ms/step - accuracy: 0.1092 - loss: 6.0011 - val_accuracy: 0.0858 - val_loss: 6.4218\n",
      "Epoch 15/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 32ms/step - accuracy: 0.1117 - loss: 5.9641 - val_accuracy: 0.0855 - val_loss: 6.4208\n",
      "Epoch 16/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 32ms/step - accuracy: 0.1144 - loss: 5.9294 - val_accuracy: 0.0870 - val_loss: 6.4261\n",
      "Epoch 17/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 32ms/step - accuracy: 0.1165 - loss: 5.8950 - val_accuracy: 0.0871 - val_loss: 6.4242\n",
      "Epoch 18/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 32ms/step - accuracy: 0.1192 - loss: 5.8639 - val_accuracy: 0.0864 - val_loss: 6.4315\n",
      "   âœ… Result: Perplexity=614.51\n",
      "\n",
      "âš¡ RUNNING EXP-02: RNN | Change layers -> 3\n",
      "Epoch 1/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 46ms/step - accuracy: 0.0374 - loss: 7.1750 - val_accuracy: 0.0382 - val_loss: 6.9614\n",
      "Epoch 2/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 46ms/step - accuracy: 0.0398 - loss: 6.9134 - val_accuracy: 0.0461 - val_loss: 6.8025\n",
      "Epoch 3/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 47ms/step - accuracy: 0.0465 - loss: 6.7659 - val_accuracy: 0.0507 - val_loss: 6.7571\n",
      "Epoch 4/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 47ms/step - accuracy: 0.0539 - loss: 6.6905 - val_accuracy: 0.0556 - val_loss: 6.6923\n",
      "Epoch 5/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 47ms/step - accuracy: 0.0629 - loss: 6.5996 - val_accuracy: 0.0627 - val_loss: 6.6325\n",
      "Epoch 6/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 47ms/step - accuracy: 0.0692 - loss: 6.5163 - val_accuracy: 0.0654 - val_loss: 6.5972\n",
      "Epoch 7/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 47ms/step - accuracy: 0.0725 - loss: 6.4528 - val_accuracy: 0.0680 - val_loss: 6.5768\n",
      "Epoch 8/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 47ms/step - accuracy: 0.0758 - loss: 6.3975 - val_accuracy: 0.0704 - val_loss: 6.5550\n",
      "Epoch 9/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 47ms/step - accuracy: 0.0790 - loss: 6.3522 - val_accuracy: 0.0705 - val_loss: 6.5514\n",
      "Epoch 10/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 48ms/step - accuracy: 0.0828 - loss: 6.3111 - val_accuracy: 0.0725 - val_loss: 6.5372\n",
      "Epoch 11/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 48ms/step - accuracy: 0.0847 - loss: 6.2747 - val_accuracy: 0.0723 - val_loss: 6.5371\n",
      "Epoch 12/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 48ms/step - accuracy: 0.0869 - loss: 6.2418 - val_accuracy: 0.0704 - val_loss: 6.5299\n",
      "Epoch 13/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 48ms/step - accuracy: 0.0904 - loss: 6.2115 - val_accuracy: 0.0717 - val_loss: 6.5255\n",
      "Epoch 14/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 49ms/step - accuracy: 0.0927 - loss: 6.1808 - val_accuracy: 0.0743 - val_loss: 6.5232\n",
      "Epoch 15/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 49ms/step - accuracy: 0.0941 - loss: 6.1545 - val_accuracy: 0.0726 - val_loss: 6.5341\n",
      "Epoch 16/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 48ms/step - accuracy: 0.0959 - loss: 6.1303 - val_accuracy: 0.0724 - val_loss: 6.5331\n",
      "Epoch 17/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 49ms/step - accuracy: 0.0963 - loss: 6.1113 - val_accuracy: 0.0723 - val_loss: 6.5260\n",
      "   âœ… Result: Perplexity=680.73\n",
      "\n",
      "âš¡ RUNNING EXP-03: RNN | Change dropout -> 0.1\n",
      "Epoch 1/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 40ms/step - accuracy: 0.0383 - loss: 7.1578 - val_accuracy: 0.0386 - val_loss: 6.9052\n",
      "Epoch 2/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 40ms/step - accuracy: 0.0417 - loss: 6.8261 - val_accuracy: 0.0489 - val_loss: 6.7590\n",
      "Epoch 3/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 40ms/step - accuracy: 0.0528 - loss: 6.6870 - val_accuracy: 0.0603 - val_loss: 6.6513\n",
      "Epoch 4/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 40ms/step - accuracy: 0.0651 - loss: 6.5629 - val_accuracy: 0.0652 - val_loss: 6.5862\n",
      "Epoch 5/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 40ms/step - accuracy: 0.0742 - loss: 6.4616 - val_accuracy: 0.0691 - val_loss: 6.5434\n",
      "Epoch 6/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 41ms/step - accuracy: 0.0822 - loss: 6.3785 - val_accuracy: 0.0733 - val_loss: 6.5164\n",
      "Epoch 7/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 41ms/step - accuracy: 0.0884 - loss: 6.3089 - val_accuracy: 0.0763 - val_loss: 6.5005\n",
      "Epoch 8/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 40ms/step - accuracy: 0.0922 - loss: 6.2473 - val_accuracy: 0.0752 - val_loss: 6.4967\n",
      "Epoch 9/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 41ms/step - accuracy: 0.0973 - loss: 6.1886 - val_accuracy: 0.0757 - val_loss: 6.4969\n",
      "Epoch 10/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 41ms/step - accuracy: 0.1012 - loss: 6.1300 - val_accuracy: 0.0762 - val_loss: 6.4961\n",
      "Epoch 11/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 41ms/step - accuracy: 0.1071 - loss: 6.0775 - val_accuracy: 0.0753 - val_loss: 6.4971\n",
      "Epoch 12/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 42ms/step - accuracy: 0.1105 - loss: 6.0282 - val_accuracy: 0.0742 - val_loss: 6.5132\n",
      "Epoch 13/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 41ms/step - accuracy: 0.1161 - loss: 5.9776 - val_accuracy: 0.0724 - val_loss: 6.5218\n",
      "   âœ… Result: Perplexity=662.54\n",
      "\n",
      "âš¡ RUNNING EXP-04: RNN | Change dropout -> 0.5\n",
      "Epoch 1/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 43ms/step - accuracy: 0.0371 - loss: 7.1754 - val_accuracy: 0.0382 - val_loss: 6.9556\n",
      "Epoch 2/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 43ms/step - accuracy: 0.0401 - loss: 6.8975 - val_accuracy: 0.0449 - val_loss: 6.8003\n",
      "Epoch 3/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 42ms/step - accuracy: 0.0447 - loss: 6.7679 - val_accuracy: 0.0515 - val_loss: 6.7369\n",
      "Epoch 4/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 39ms/step - accuracy: 0.0543 - loss: 6.6761 - val_accuracy: 0.0580 - val_loss: 6.6606\n",
      "Epoch 5/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 40ms/step - accuracy: 0.0601 - loss: 6.6023 - val_accuracy: 0.0609 - val_loss: 6.6216\n",
      "Epoch 6/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 42ms/step - accuracy: 0.0644 - loss: 6.5443 - val_accuracy: 0.0651 - val_loss: 6.5890\n",
      "Epoch 7/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 39ms/step - accuracy: 0.0676 - loss: 6.4985 - val_accuracy: 0.0649 - val_loss: 6.5675\n",
      "Epoch 8/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 39ms/step - accuracy: 0.0699 - loss: 6.4600 - val_accuracy: 0.0698 - val_loss: 6.5497\n",
      "Epoch 9/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 44ms/step - accuracy: 0.0730 - loss: 6.4241 - val_accuracy: 0.0702 - val_loss: 6.5311\n",
      "Epoch 10/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 45ms/step - accuracy: 0.0757 - loss: 6.3952 - val_accuracy: 0.0697 - val_loss: 6.5188\n",
      "Epoch 11/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 42ms/step - accuracy: 0.0768 - loss: 6.3670 - val_accuracy: 0.0707 - val_loss: 6.5118\n",
      "Epoch 12/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 47ms/step - accuracy: 0.0790 - loss: 6.3437 - val_accuracy: 0.0734 - val_loss: 6.5022\n",
      "Epoch 13/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 44ms/step - accuracy: 0.0800 - loss: 6.3217 - val_accuracy: 0.0732 - val_loss: 6.4987\n",
      "Epoch 14/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 44ms/step - accuracy: 0.0812 - loss: 6.2993 - val_accuracy: 0.0739 - val_loss: 6.4900\n",
      "Epoch 15/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 45ms/step - accuracy: 0.0827 - loss: 6.2797 - val_accuracy: 0.0739 - val_loss: 6.4858\n",
      "Epoch 16/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 50ms/step - accuracy: 0.0843 - loss: 6.2606 - val_accuracy: 0.0750 - val_loss: 6.4814\n",
      "Epoch 17/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 46ms/step - accuracy: 0.0851 - loss: 6.2445 - val_accuracy: 0.0775 - val_loss: 6.4790\n",
      "Epoch 18/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 48ms/step - accuracy: 0.0864 - loss: 6.2286 - val_accuracy: 0.0756 - val_loss: 6.4798\n",
      "Epoch 19/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 46ms/step - accuracy: 0.0876 - loss: 6.2173 - val_accuracy: 0.0771 - val_loss: 6.4707\n",
      "Epoch 20/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 45ms/step - accuracy: 0.0878 - loss: 6.2009 - val_accuracy: 0.0779 - val_loss: 6.4648\n",
      "   âœ… Result: Perplexity=642.16\n",
      "\n",
      "âš¡ RUNNING EXP-05: RNN | Change lr -> 0.01\n",
      "Epoch 1/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 46ms/step - accuracy: 0.0198 - loss: 7.5232 - val_accuracy: 0.0202 - val_loss: 8.0366\n",
      "Epoch 2/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 46ms/step - accuracy: 0.0189 - loss: 7.6236 - val_accuracy: 0.0133 - val_loss: 7.8396\n",
      "Epoch 3/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 48ms/step - accuracy: 0.0197 - loss: 7.4571 - val_accuracy: 0.0151 - val_loss: 7.8360\n",
      "Epoch 4/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 47ms/step - accuracy: 0.0206 - loss: 7.4451 - val_accuracy: 0.0181 - val_loss: 7.7491\n",
      "Epoch 5/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 47ms/step - accuracy: 0.0201 - loss: 7.4456 - val_accuracy: 0.0183 - val_loss: 7.8474\n",
      "Epoch 6/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 47ms/step - accuracy: 0.0205 - loss: 7.4526 - val_accuracy: 0.0163 - val_loss: 7.7638\n",
      "Epoch 7/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 47ms/step - accuracy: 0.0200 - loss: 7.4423 - val_accuracy: 0.0158 - val_loss: 7.7748\n",
      "   âœ… Result: Perplexity=2319.56\n",
      "\n",
      "âš¡ RUNNING EXP-06: RNN | Change lr -> 0.0001\n",
      "Epoch 1/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 48ms/step - accuracy: 0.0289 - loss: 8.0829 - val_accuracy: 0.0382 - val_loss: 6.9587\n",
      "Epoch 2/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 46ms/step - accuracy: 0.0401 - loss: 6.9193 - val_accuracy: 0.0382 - val_loss: 6.9275\n",
      "Epoch 3/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 47ms/step - accuracy: 0.0401 - loss: 6.8969 - val_accuracy: 0.0382 - val_loss: 6.9227\n",
      "Epoch 4/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 47ms/step - accuracy: 0.0401 - loss: 6.8931 - val_accuracy: 0.0382 - val_loss: 6.9218\n",
      "Epoch 5/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 47ms/step - accuracy: 0.0401 - loss: 6.8923 - val_accuracy: 0.0382 - val_loss: 6.9216\n",
      "Epoch 6/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 47ms/step - accuracy: 0.0401 - loss: 6.8921 - val_accuracy: 0.0382 - val_loss: 6.9215\n",
      "Epoch 7/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 48ms/step - accuracy: 0.0401 - loss: 6.8921 - val_accuracy: 0.0382 - val_loss: 6.9215\n",
      "Epoch 8/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 50ms/step - accuracy: 0.0401 - loss: 6.8921 - val_accuracy: 0.0382 - val_loss: 6.9215\n",
      "Epoch 9/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 49ms/step - accuracy: 0.0401 - loss: 6.8921 - val_accuracy: 0.0382 - val_loss: 6.9215\n",
      "Epoch 10/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 47ms/step - accuracy: 0.0401 - loss: 6.8921 - val_accuracy: 0.0382 - val_loss: 6.9215\n",
      "Epoch 11/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 48ms/step - accuracy: 0.0401 - loss: 6.8921 - val_accuracy: 0.0382 - val_loss: 6.9215\n",
      "Epoch 12/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 48ms/step - accuracy: 0.0401 - loss: 6.8921 - val_accuracy: 0.0382 - val_loss: 6.9215\n",
      "   âœ… Result: Perplexity=1013.86\n",
      "\n",
      "âš¡ RUNNING EXP-07: RNN | Change batch -> 64\n",
      "Epoch 1/20\n",
      "\u001b[1m2149/2149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 34ms/step - accuracy: 0.0373 - loss: 7.1515 - val_accuracy: 0.0443 - val_loss: 6.8839\n",
      "Epoch 2/20\n",
      "\u001b[1m2149/2149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 34ms/step - accuracy: 0.0474 - loss: 6.8304 - val_accuracy: 0.0565 - val_loss: 6.7566\n",
      "Epoch 3/20\n",
      "\u001b[1m2149/2149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 34ms/step - accuracy: 0.0605 - loss: 6.6917 - val_accuracy: 0.0648 - val_loss: 6.6897\n",
      "Epoch 4/20\n",
      "\u001b[1m2149/2149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 34ms/step - accuracy: 0.0695 - loss: 6.6090 - val_accuracy: 0.0686 - val_loss: 6.6447\n",
      "Epoch 5/20\n",
      "\u001b[1m2149/2149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 34ms/step - accuracy: 0.0767 - loss: 6.5429 - val_accuracy: 0.0721 - val_loss: 6.6205\n",
      "Epoch 6/20\n",
      "\u001b[1m2149/2149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 35ms/step - accuracy: 0.0821 - loss: 6.4923 - val_accuracy: 0.0742 - val_loss: 6.6053\n",
      "Epoch 7/20\n",
      "\u001b[1m2149/2149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 35ms/step - accuracy: 0.0852 - loss: 6.4535 - val_accuracy: 0.0768 - val_loss: 6.5963\n",
      "Epoch 8/20\n",
      "\u001b[1m2149/2149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 35ms/step - accuracy: 0.0887 - loss: 6.4108 - val_accuracy: 0.0769 - val_loss: 6.5832\n",
      "Epoch 9/20\n",
      "\u001b[1m2149/2149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 35ms/step - accuracy: 0.0907 - loss: 6.3767 - val_accuracy: 0.0781 - val_loss: 6.5759\n",
      "Epoch 10/20\n",
      "\u001b[1m2149/2149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 36ms/step - accuracy: 0.0930 - loss: 6.3441 - val_accuracy: 0.0782 - val_loss: 6.5723\n",
      "Epoch 11/20\n",
      "\u001b[1m2149/2149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 35ms/step - accuracy: 0.0959 - loss: 6.3164 - val_accuracy: 0.0816 - val_loss: 6.5620\n",
      "Epoch 12/20\n",
      "\u001b[1m2149/2149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 36ms/step - accuracy: 0.0987 - loss: 6.2889 - val_accuracy: 0.0795 - val_loss: 6.5637\n",
      "Epoch 13/20\n",
      "\u001b[1m2149/2149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 36ms/step - accuracy: 0.1002 - loss: 6.2636 - val_accuracy: 0.0814 - val_loss: 6.5545\n",
      "Epoch 14/20\n",
      "\u001b[1m2149/2149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 36ms/step - accuracy: 0.1021 - loss: 6.2428 - val_accuracy: 0.0818 - val_loss: 6.5520\n",
      "Epoch 15/20\n",
      "\u001b[1m2149/2149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 36ms/step - accuracy: 0.1039 - loss: 6.2216 - val_accuracy: 0.0799 - val_loss: 6.5573\n",
      "Epoch 16/20\n",
      "\u001b[1m2149/2149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 36ms/step - accuracy: 0.1060 - loss: 6.2018 - val_accuracy: 0.0806 - val_loss: 6.5562\n",
      "Epoch 17/20\n",
      "\u001b[1m2149/2149\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 37ms/step - accuracy: 0.1084 - loss: 6.1843 - val_accuracy: 0.0793 - val_loss: 6.5534\n",
      "   âœ… Result: Perplexity=700.62\n",
      "\n",
      "âš¡ RUNNING EXP-08: RNN | Change batch -> 256\n",
      "Epoch 1/20\n",
      "\u001b[1m538/538\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 83ms/step - accuracy: 0.0378 - loss: 7.2117 - val_accuracy: 0.0382 - val_loss: 6.9167\n",
      "Epoch 2/20\n",
      "\u001b[1m538/538\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 83ms/step - accuracy: 0.0398 - loss: 6.8852 - val_accuracy: 0.0382 - val_loss: 6.8955\n",
      "Epoch 3/20\n",
      "\u001b[1m538/538\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 83ms/step - accuracy: 0.0408 - loss: 6.8345 - val_accuracy: 0.0457 - val_loss: 6.7556\n",
      "Epoch 4/20\n",
      "\u001b[1m538/538\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 83ms/step - accuracy: 0.0476 - loss: 6.7024 - val_accuracy: 0.0491 - val_loss: 6.7133\n",
      "Epoch 5/20\n",
      "\u001b[1m538/538\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 83ms/step - accuracy: 0.0557 - loss: 6.6077 - val_accuracy: 0.0562 - val_loss: 6.6184\n",
      "Epoch 6/20\n",
      "\u001b[1m538/538\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 83ms/step - accuracy: 0.0645 - loss: 6.5074 - val_accuracy: 0.0606 - val_loss: 6.5644\n",
      "Epoch 7/20\n",
      "\u001b[1m538/538\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 86ms/step - accuracy: 0.0703 - loss: 6.4223 - val_accuracy: 0.0618 - val_loss: 6.5323\n",
      "Epoch 8/20\n",
      "\u001b[1m538/538\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 85ms/step - accuracy: 0.0754 - loss: 6.3481 - val_accuracy: 0.0640 - val_loss: 6.5117\n",
      "Epoch 9/20\n",
      "\u001b[1m538/538\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 84ms/step - accuracy: 0.0805 - loss: 6.2775 - val_accuracy: 0.0654 - val_loss: 6.4925\n",
      "Epoch 10/20\n",
      "\u001b[1m538/538\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 84ms/step - accuracy: 0.0868 - loss: 6.2140 - val_accuracy: 0.0679 - val_loss: 6.4849\n",
      "Epoch 11/20\n",
      "\u001b[1m538/538\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 85ms/step - accuracy: 0.0912 - loss: 6.1577 - val_accuracy: 0.0678 - val_loss: 6.4737\n",
      "Epoch 12/20\n",
      "\u001b[1m538/538\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 84ms/step - accuracy: 0.0952 - loss: 6.0999 - val_accuracy: 0.0710 - val_loss: 6.4733\n",
      "Epoch 13/20\n",
      "\u001b[1m538/538\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 85ms/step - accuracy: 0.0988 - loss: 6.0466 - val_accuracy: 0.0707 - val_loss: 6.4843\n",
      "Epoch 14/20\n",
      "\u001b[1m538/538\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 86ms/step - accuracy: 0.1023 - loss: 5.9992 - val_accuracy: 0.0692 - val_loss: 6.4967\n",
      "Epoch 15/20\n",
      "\u001b[1m538/538\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 84ms/step - accuracy: 0.1057 - loss: 5.9520 - val_accuracy: 0.0708 - val_loss: 6.4962\n",
      "   âœ… Result: Perplexity=647.59\n",
      "\n",
      "âš¡ RUNNING EXP-09: RNN | Change seq_len -> 10\n",
      "   Note: Temporarily re-processing raw data for Seq Len 10...\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherr\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 32ms/step - accuracy: 0.0370 - loss: 7.1140 - val_accuracy: 0.0383 - val_loss: 6.8329\n",
      "Epoch 2/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 32ms/step - accuracy: 0.0420 - loss: 6.7635 - val_accuracy: 0.0496 - val_loss: 6.6871\n",
      "Epoch 3/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 32ms/step - accuracy: 0.0538 - loss: 6.6150 - val_accuracy: 0.0595 - val_loss: 6.5846\n",
      "Epoch 4/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 32ms/step - accuracy: 0.0654 - loss: 6.4978 - val_accuracy: 0.0664 - val_loss: 6.5227\n",
      "Epoch 5/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 33ms/step - accuracy: 0.0729 - loss: 6.4052 - val_accuracy: 0.0725 - val_loss: 6.4913\n",
      "Epoch 6/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 33ms/step - accuracy: 0.0803 - loss: 6.3355 - val_accuracy: 0.0760 - val_loss: 6.4710\n",
      "Epoch 7/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 33ms/step - accuracy: 0.0854 - loss: 6.2722 - val_accuracy: 0.0762 - val_loss: 6.4608\n",
      "Epoch 8/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 33ms/step - accuracy: 0.0899 - loss: 6.2195 - val_accuracy: 0.0765 - val_loss: 6.4591\n",
      "Epoch 9/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 33ms/step - accuracy: 0.0922 - loss: 6.1695 - val_accuracy: 0.0782 - val_loss: 6.4602\n",
      "Epoch 10/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 33ms/step - accuracy: 0.0968 - loss: 6.1224 - val_accuracy: 0.0754 - val_loss: 6.4657\n",
      "Epoch 11/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 33ms/step - accuracy: 0.0998 - loss: 6.0835 - val_accuracy: 0.0782 - val_loss: 6.4580\n",
      "Epoch 12/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 33ms/step - accuracy: 0.1033 - loss: 6.0417 - val_accuracy: 0.0766 - val_loss: 6.4686\n",
      "Epoch 13/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 33ms/step - accuracy: 0.1062 - loss: 6.0041 - val_accuracy: 0.0765 - val_loss: 6.4745\n",
      "Epoch 14/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 34ms/step - accuracy: 0.1094 - loss: 5.9691 - val_accuracy: 0.0755 - val_loss: 6.4878\n",
      "   âœ… Result: Perplexity=637.80\n",
      "\n",
      "âš¡ RUNNING EXP-10: RNN | Change seq_len -> 30\n",
      "   Note: Temporarily re-processing raw data for Seq Len 30...\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherr\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 49ms/step - accuracy: 0.0364 - loss: 7.1050 - val_accuracy: 0.0380 - val_loss: 6.8953\n",
      "Epoch 2/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 48ms/step - accuracy: 0.0400 - loss: 6.8079 - val_accuracy: 0.0493 - val_loss: 6.7239\n",
      "Epoch 3/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 47ms/step - accuracy: 0.0507 - loss: 6.6673 - val_accuracy: 0.0545 - val_loss: 6.6351\n",
      "Epoch 4/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 48ms/step - accuracy: 0.0622 - loss: 6.5469 - val_accuracy: 0.0629 - val_loss: 6.5579\n",
      "Epoch 5/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 48ms/step - accuracy: 0.0687 - loss: 6.4592 - val_accuracy: 0.0660 - val_loss: 6.5136\n",
      "Epoch 6/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 48ms/step - accuracy: 0.0738 - loss: 6.3846 - val_accuracy: 0.0720 - val_loss: 6.4783\n",
      "Epoch 7/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 49ms/step - accuracy: 0.0792 - loss: 6.3228 - val_accuracy: 0.0743 - val_loss: 6.4584\n",
      "Epoch 8/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 48ms/step - accuracy: 0.0836 - loss: 6.2705 - val_accuracy: 0.0757 - val_loss: 6.4456\n",
      "Epoch 9/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 48ms/step - accuracy: 0.0873 - loss: 6.2245 - val_accuracy: 0.0771 - val_loss: 6.4350\n",
      "Epoch 10/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 49ms/step - accuracy: 0.0909 - loss: 6.1801 - val_accuracy: 0.0775 - val_loss: 6.4332\n",
      "Epoch 11/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 49ms/step - accuracy: 0.0946 - loss: 6.1403 - val_accuracy: 0.0792 - val_loss: 6.4255\n",
      "Epoch 12/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 49ms/step - accuracy: 0.0969 - loss: 6.1030 - val_accuracy: 0.0796 - val_loss: 6.4310\n",
      "Epoch 13/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 49ms/step - accuracy: 0.0994 - loss: 6.0673 - val_accuracy: 0.0783 - val_loss: 6.4274\n",
      "Epoch 14/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 49ms/step - accuracy: 0.1023 - loss: 6.0343 - val_accuracy: 0.0790 - val_loss: 6.4280\n",
      "   âœ… Result: Perplexity=617.41\n",
      "\n",
      "âš¡ RUNNING EXP-11: Trans | Change heads -> 2\n",
      "WARNING:tensorflow:From C:\\Users\\sherr\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Epoch 1/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 120ms/step - accuracy: 0.0379 - loss: 7.1992 - val_accuracy: 0.0382 - val_loss: 6.9720\n",
      "Epoch 2/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 115ms/step - accuracy: 0.0398 - loss: 6.9615 - val_accuracy: 0.0382 - val_loss: 6.9648\n",
      "Epoch 3/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 115ms/step - accuracy: 0.0399 - loss: 6.9786 - val_accuracy: 0.0382 - val_loss: 6.9612\n",
      "Epoch 4/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 115ms/step - accuracy: 0.0401 - loss: 6.9896 - val_accuracy: 0.0382 - val_loss: 6.9690\n",
      "Epoch 5/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 114ms/step - accuracy: 0.0399 - loss: 6.9880 - val_accuracy: 0.0382 - val_loss: 6.9827\n",
      "Epoch 6/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 114ms/step - accuracy: 0.0398 - loss: 6.9743 - val_accuracy: 0.0362 - val_loss: 6.9894\n",
      "   âœ… Result: Perplexity=1054.88\n",
      "\n",
      "âš¡ RUNNING EXP-12: Trans | Change heads -> 8\n",
      "Epoch 1/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 215ms/step - accuracy: 0.0390 - loss: 7.1966 - val_accuracy: 0.0382 - val_loss: 6.9647\n",
      "Epoch 2/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 209ms/step - accuracy: 0.0398 - loss: 6.9672 - val_accuracy: 0.0382 - val_loss: 6.9559\n",
      "Epoch 3/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 209ms/step - accuracy: 0.0400 - loss: 6.9865 - val_accuracy: 0.0382 - val_loss: 6.9590\n",
      "Epoch 4/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 210ms/step - accuracy: 0.0400 - loss: 6.9917 - val_accuracy: 0.0382 - val_loss: 6.9594\n",
      "Epoch 5/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 209ms/step - accuracy: 0.0400 - loss: 6.9884 - val_accuracy: 0.0382 - val_loss: 6.9718\n",
      "   âœ… Result: Perplexity=1049.36\n",
      "\n",
      "âš¡ RUNNING EXP-13: Trans | Change ff_dim -> 256\n",
      "Epoch 1/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 132ms/step - accuracy: 0.0374 - loss: 7.1967 - val_accuracy: 0.0382 - val_loss: 6.9719\n",
      "Epoch 2/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 132ms/step - accuracy: 0.0400 - loss: 6.9668 - val_accuracy: 0.0382 - val_loss: 6.9549\n",
      "Epoch 3/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 132ms/step - accuracy: 0.0400 - loss: 6.9850 - val_accuracy: 0.0382 - val_loss: 6.9532\n",
      "Epoch 4/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 133ms/step - accuracy: 0.0400 - loss: 6.9932 - val_accuracy: 0.0382 - val_loss: 6.9636\n",
      "Epoch 5/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 132ms/step - accuracy: 0.0399 - loss: 6.9904 - val_accuracy: 0.0382 - val_loss: 6.9699\n",
      "Epoch 6/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 131ms/step - accuracy: 0.0396 - loss: 6.9746 - val_accuracy: 0.0379 - val_loss: 6.9672\n",
      "   âœ… Result: Perplexity=1046.48\n",
      "\n",
      "âš¡ RUNNING EXP-14: Trans | Change blocks -> 1\n",
      "Epoch 1/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 90ms/step - accuracy: 0.0375 - loss: 7.1995 - val_accuracy: 0.0382 - val_loss: 6.9755\n",
      "Epoch 2/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 90ms/step - accuracy: 0.0399 - loss: 6.9650 - val_accuracy: 0.0382 - val_loss: 6.9633\n",
      "Epoch 3/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 90ms/step - accuracy: 0.0407 - loss: 6.9678 - val_accuracy: 0.0360 - val_loss: 6.8955\n",
      "Epoch 4/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 90ms/step - accuracy: 0.0444 - loss: 6.8952 - val_accuracy: 0.0398 - val_loss: 6.8154\n",
      "Epoch 5/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 92ms/step - accuracy: 0.0492 - loss: 6.7877 - val_accuracy: 0.0436 - val_loss: 6.7738\n",
      "Epoch 6/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 100ms/step - accuracy: 0.0592 - loss: 6.6371 - val_accuracy: 0.0703 - val_loss: 6.5707\n",
      "Epoch 7/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 92ms/step - accuracy: 0.0840 - loss: 6.4014 - val_accuracy: 0.0783 - val_loss: 6.5131\n",
      "Epoch 8/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 91ms/step - accuracy: 0.0969 - loss: 6.2470 - val_accuracy: 0.0812 - val_loss: 6.4893\n",
      "Epoch 9/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 91ms/step - accuracy: 0.1111 - loss: 6.1225 - val_accuracy: 0.0813 - val_loss: 6.5201\n",
      "Epoch 10/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 91ms/step - accuracy: 0.1246 - loss: 6.0055 - val_accuracy: 0.0828 - val_loss: 6.5653\n",
      "Epoch 11/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 91ms/step - accuracy: 0.1378 - loss: 5.8957 - val_accuracy: 0.0801 - val_loss: 6.6281\n",
      "   âœ… Result: Perplexity=658.08\n",
      "\n",
      "âš¡ RUNNING EXP-15: Trans | Change blocks -> 3\n",
      "Epoch 1/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 214ms/step - accuracy: 0.0377 - loss: 7.1976 - val_accuracy: 0.0382 - val_loss: 6.9675\n",
      "Epoch 2/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 210ms/step - accuracy: 0.0398 - loss: 6.9647 - val_accuracy: 0.0382 - val_loss: 6.9586\n",
      "Epoch 3/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 209ms/step - accuracy: 0.0400 - loss: 6.9844 - val_accuracy: 0.0382 - val_loss: 6.9546\n",
      "Epoch 4/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 210ms/step - accuracy: 0.0400 - loss: 6.9891 - val_accuracy: 0.0382 - val_loss: 6.9609\n",
      "Epoch 5/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 210ms/step - accuracy: 0.0400 - loss: 6.9845 - val_accuracy: 0.0382 - val_loss: 6.9792\n",
      "Epoch 6/20\n",
      "\u001b[1m1075/1075\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 208ms/step - accuracy: 0.0400 - loss: 6.9793 - val_accuracy: 0.0382 - val_loss: 6.9749\n",
      "   âœ… Result: Perplexity=1047.99\n",
      "\n",
      " Hyperparameter Tuning Complete!\n",
      "        ID  Model Parameter     Value  Perplexity    Loss  Time(s)\n",
      "0   EXP-01    RNN    layers    1.0000      614.51  6.4208    589.8\n",
      "1   EXP-02    RNN    layers    3.0000      680.73  6.5232    873.8\n",
      "2   EXP-03    RNN   dropout    0.1000      662.54  6.4961    570.7\n",
      "3   EXP-04    RNN   dropout    0.5000      642.16  6.4648    977.1\n",
      "4   EXP-05    RNN        lr    0.0100     2319.56  7.7491    356.0\n",
      "5   EXP-06    RNN        lr    0.0001     1013.86  6.9215    618.4\n",
      "6   EXP-07    RNN     batch   64.0000      700.62  6.5520   1292.5\n",
      "7   EXP-08    RNN     batch  256.0000      647.59  6.4733    682.4\n",
      "8   EXP-09    RNN   seq_len   10.0000      637.80  6.4580    497.2\n",
      "9   EXP-10    RNN   seq_len   30.0000      617.41  6.4255    733.0\n",
      "10  EXP-11  Trans     heads    2.0000     1054.88  6.9612    749.6\n",
      "11  EXP-12  Trans     heads    8.0000     1049.36  6.9559   1136.9\n",
      "12  EXP-13  Trans    ff_dim  256.0000     1046.48  6.9532    858.9\n",
      "13  EXP-14  Trans    blocks    1.0000      658.08  6.4893   1088.4\n",
      "14  EXP-15  Trans    blocks    3.0000     1047.99  6.9546   1362.9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Embedding, SimpleRNN, LSTM, Dense, Dropout, LayerNormalization, MultiHeadAttention, GlobalAveragePooling1D, Layer\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "os.makedirs('../results/tables', exist_ok=True)\n",
    "CSV_PATH = '../results/tables/hyperparameter_results.csv'\n",
    "\n",
    "# Data Loading\n",
    "\n",
    "def load_ready_data():\n",
    "    \"\"\"Loads the standard preprocessed data (Seq Len ~20)\"\"\"\n",
    "    data = np.load('../data/processed/ready_data.npz')\n",
    "    X_train = data['X_train']\n",
    "    y_train = data['y_train']\n",
    "    X_val = data['X_val']\n",
    "    y_val = data['y_val']\n",
    "    total_words = int(data['total_words'])\n",
    "    max_sequence_len = X_train.shape[1] + 1\n",
    "    return X_train, y_train, X_val, y_val, total_words, max_sequence_len\n",
    "\n",
    "def load_and_process_raw_data(new_seq_len):\n",
    "    print(f\"   Note: Temporarily re-processing raw data for Seq Len {new_seq_len}...\")\n",
    "    df = pd.read_csv('../data/urdu_poetry_raw.csv')\n",
    "    \n",
    "    # Loading the  tokenizer\n",
    "    with open('../models/tokenizer.pickle', 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "    \n",
    "    # Checking column name\n",
    "    col_name = 'cleaned_text' if 'cleaned_text' in df.columns else 'Content'\n",
    "    if col_name not in df.columns:\n",
    "        # Fallback for case sensitivity\n",
    "        col_name = 'content' \n",
    "        \n",
    "    corpus = df[col_name].astype(str).tolist()\n",
    "        \n",
    "    input_sequences = []\n",
    "    for line in corpus:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "            \n",
    "    # Padding with NEW length\n",
    "    input_sequences = np.array(pad_sequences(input_sequences, \n",
    "                                             maxlen=new_seq_len, \n",
    "                                             padding='pre', \n",
    "                                             truncating='pre'))\n",
    "    \n",
    "    X = input_sequences[:, :-1]\n",
    "    y = input_sequences[:, -1]\n",
    "    \n",
    "    # Split\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=SEED)\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "# Model building\n",
    "\n",
    "def build_rnn_dynamic(vocab_size, seq_len, units, layers, dropout):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 100, input_length=seq_len-1))\n",
    "    \n",
    "    # Add stacked layers\n",
    "    for i in range(layers - 1):\n",
    "        model.add(SimpleRNN(units, return_sequences=True, dropout=dropout))\n",
    "    \n",
    "    # Final RNN layer\n",
    "    model.add(SimpleRNN(units, return_sequences=False, dropout=dropout))\n",
    "    model.add(Dense(vocab_size, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# Transformer Components\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1, **kwargs):\n",
    "        super(TransformerBlock, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.rate = rate\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = Sequential([Dense(ff_dim, activation=\"relu\"), Dense(embed_dim),])\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"ff_dim\": self.ff_dim,\n",
    "            \"rate\": self.rate,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class TokenAndPositionEmbedding(Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim, **kwargs):\n",
    "        super(TokenAndPositionEmbedding, self).__init__(**kwargs)\n",
    "        self.maxlen = maxlen\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.token_emb = Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"maxlen\": self.maxlen,\n",
    "            \"vocab_size\": self.vocab_size,\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "def build_transformer_dynamic(vocab_size, seq_len, heads, ff_dim, blocks, dropout):\n",
    "    inputs = Input(shape=(seq_len-1,))\n",
    "    embedding_layer = TokenAndPositionEmbedding(seq_len-1, vocab_size, 100)\n",
    "    x = embedding_layer(inputs)\n",
    "    \n",
    "    for _ in range(blocks):\n",
    "        x = TransformerBlock(100, heads, ff_dim, rate=dropout)(x)\n",
    "        \n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    outputs = Dense(vocab_size, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=\"Transformer\")\n",
    "    return model\n",
    "\n",
    "# Experiment Definition and Execution\n",
    "\n",
    "# Baseline: RNN, RMSprop, 2 Layers, 0.2 Dropout, 0.001 LR, 128 Batch, 20 Seq\n",
    "experiments = [\n",
    "    # --- ARCHITECTURE (RNN) ---\n",
    "    {\"id\": \"EXP-01\", \"type\": \"RNN\", \"param\": \"layers\", \"val\": 1, \"config\": {\"layers\": 1}},\n",
    "    {\"id\": \"EXP-02\", \"type\": \"RNN\", \"param\": \"layers\", \"val\": 3, \"config\": {\"layers\": 3}},\n",
    "    {\"id\": \"EXP-03\", \"type\": \"RNN\", \"param\": \"dropout\", \"val\": 0.1, \"config\": {\"dropout\": 0.1}},\n",
    "    {\"id\": \"EXP-04\", \"type\": \"RNN\", \"param\": \"dropout\", \"val\": 0.5, \"config\": {\"dropout\": 0.5}},\n",
    "    \n",
    "    # --- TRAINING (RNN) ---\n",
    "    {\"id\": \"EXP-05\", \"type\": \"RNN\", \"param\": \"lr\", \"val\": 0.01, \"config\": {\"lr\": 0.01}},\n",
    "    {\"id\": \"EXP-06\", \"type\": \"RNN\", \"param\": \"lr\", \"val\": 0.0001, \"config\": {\"lr\": 0.0001}},\n",
    "    {\"id\": \"EXP-07\", \"type\": \"RNN\", \"param\": \"batch\", \"val\": 64, \"config\": {\"batch\": 64}},\n",
    "    {\"id\": \"EXP-08\", \"type\": \"RNN\", \"param\": \"batch\", \"val\": 256, \"config\": {\"batch\": 256}},\n",
    "    \n",
    "    # --- SEQUENCE LENGTH (RNN) - Requires Data Reload ---\n",
    "    {\"id\": \"EXP-09\", \"type\": \"RNN\", \"param\": \"seq_len\", \"val\": 10, \"config\": {\"seq_len\": 10}},\n",
    "    {\"id\": \"EXP-10\", \"type\": \"RNN\", \"param\": \"seq_len\", \"val\": 30, \"config\": {\"seq_len\": 30}},\n",
    "    \n",
    "    # --- TRANSFORMER SPECIFIC ---\n",
    "    # Base: Heads=4, FF=512, Blocks=2\n",
    "    {\"id\": \"EXP-11\", \"type\": \"Trans\", \"param\": \"heads\", \"val\": 2, \"config\": {\"heads\": 2}},\n",
    "    {\"id\": \"EXP-12\", \"type\": \"Trans\", \"param\": \"heads\", \"val\": 8, \"config\": {\"heads\": 8}},\n",
    "    {\"id\": \"EXP-13\", \"type\": \"Trans\", \"param\": \"ff_dim\", \"val\": 256, \"config\": {\"ff_dim\": 256}},\n",
    "    {\"id\": \"EXP-14\", \"type\": \"Trans\", \"param\": \"blocks\", \"val\": 1, \"config\": {\"blocks\": 1}},\n",
    "    {\"id\": \"EXP-15\", \"type\": \"Trans\", \"param\": \"blocks\", \"val\": 3, \"config\": {\"blocks\": 3}},\n",
    "]\n",
    "\n",
    "#Execution Loop\n",
    "\n",
    "# Loading  Default Data First\n",
    "print(\" Loading Standard Dataset...\")\n",
    "X_train_def, y_train_def, X_val_def, y_val_def, total_words, max_seq_len_def = load_ready_data()\n",
    "\n",
    "print(f\" Starting {len(experiments)} Hyperparameter Experiments...\")\n",
    "\n",
    "# Logic to check existing results for resumption\n",
    "completed_ids = set()\n",
    "if os.path.exists(CSV_PATH):\n",
    "    try:\n",
    "        existing_df = pd.read_csv(CSV_PATH)\n",
    "        completed_ids = set(existing_df['ID'].unique())\n",
    "        print(f\" Resuming... Found {len(completed_ids)} completed experiments.\")\n",
    "    except:\n",
    "        print(\" CSV file exists but is empty or corrupt. Starting fresh.\")\n",
    "\n",
    "for exp in experiments:\n",
    "    exp_id = exp['id']\n",
    "    \n",
    "    if exp_id in completed_ids:\n",
    "        print(f\"â­ï¸  Skipping {exp_id} (Already Complete)\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n RUNNING {exp['id']}: {exp['type']} | Change {exp['param']} -> {exp['val']}\")\n",
    "    \n",
    "    # Setting defaults\n",
    "    cfg = {\n",
    "        \"units\": 128, \"layers\": 2, \"dropout\": 0.2, \n",
    "        \"lr\": 0.001, \"batch\": 128, \"seq_len\": max_seq_len_def,\n",
    "        \"heads\": 4, \"ff_dim\": 512, \"blocks\": 2\n",
    "    }\n",
    "    cfg.update(exp['config'])\n",
    "    \n",
    "    #  Preparing Data\n",
    "    if exp['param'] == 'seq_len':\n",
    "        X_t, y_t, X_v, y_v = load_and_process_raw_data(cfg['seq_len'])\n",
    "        curr_seq_len = cfg['seq_len']\n",
    "    else:\n",
    "        X_t, y_t, X_v, y_v = X_train_def, y_train_def, X_val_def, y_val_def\n",
    "        curr_seq_len = max_seq_len_def\n",
    "\n",
    "    #  Build Model\n",
    "    if exp['type'] == \"RNN\":\n",
    "        model = build_rnn_dynamic(total_words, curr_seq_len, cfg['units'], cfg['layers'], cfg['dropout'])\n",
    "        opt = RMSprop(learning_rate=cfg['lr']) \n",
    "    else:\n",
    "        model = build_transformer_dynamic(total_words, curr_seq_len, cfg['heads'], cfg['ff_dim'], cfg['blocks'], cfg['dropout'])\n",
    "        opt = RMSprop(learning_rate=cfg['lr']) \n",
    "        \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    #  Train\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_t, y_t,\n",
    "        epochs=20, \n",
    "        batch_size=cfg['batch'],\n",
    "        validation_data=(X_v, y_v),\n",
    "        callbacks=[EarlyStopping(patience=3, monitor='val_loss', restore_best_weights=True)],\n",
    "        verbose=1 # CHANGED TO 1 FOR VISIBILITY\n",
    "    )\n",
    "    duration = time.time() - start_time\n",
    "    \n",
    "    #  Log & Save Immediately\n",
    "    best_loss = min(history.history['val_loss'])\n",
    "    perplexity = np.exp(best_loss)\n",
    "    \n",
    "    print(f\"    Result: Perplexity={perplexity:.2f}\")\n",
    "    \n",
    "    result_entry = {\n",
    "        \"ID\": exp['id'],\n",
    "        \"Model\": exp['type'],\n",
    "        \"Parameter\": exp['param'],\n",
    "        \"Value\": exp['val'],\n",
    "        \"Perplexity\": round(perplexity, 2),\n",
    "        \"Loss\": round(best_loss, 4),\n",
    "        \"Time(s)\": round(duration, 1)\n",
    "    }\n",
    "    \n",
    "    # Save to CSV immediately \n",
    "    df_row = pd.DataFrame([result_entry])\n",
    "    df_row.to_csv(CSV_PATH, mode='a', header=not os.path.exists(CSV_PATH), index=False)\n",
    "\n",
    "print(\"\\n Hyperparameter Tuning Complete!\")\n",
    "if os.path.exists(CSV_PATH):\n",
    "    print(pd.read_csv(CSV_PATH))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
